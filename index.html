<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>From Seeing to Feeling: Visual Affordance Guided Active Tactile Verification for Reliable Deformable Object Manipulation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <style>
  .small-video {
    width: 60%;
    height: auto;
  }
  </style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">From Seeing to Feeling: Visual Affordance Guided Active Tactile Verification for Reliable Deformable Object Manipulation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Anonymous Authors</span>
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/VATV1/From-Seeing-to-Feeling"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/drive/folders/1gN2t7nQUk-_fB5gUaljWAj0KF0KWqmji?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
Despite the remarkable progress in robotic manipulation of rigid objects, the manipulation of deformable objects remains a significant challenge due to their complex physical uncertainties. Existing methods are predominantly vision-based and thus incapable of perceiving deformable objectsâ€™ intrinsic physical properties (softness), overlooking the essential role of tactile sensing in understanding physical interaction dynamics. To address these challenges, we propose a Visual Affordance Guided Active Tactile Verification (VATV) framework that enables reliable deformable object manipulation for robots.
Specifically, to achieve keypoint detection for unseen deformable objects with minimal training samples, we introduce a One-Shot Visual Affordance Learning (OS-VAL) network. OS-VAL enhances keypoint representations through geometric constraints and guides the network to focus on critical regions of deformable objects via a saliency mechanism. OS-VAL achieves generalization to novel instances within the same object category using only a single training sample. Subsequently, the robot actively touches the keypoints suggested by OS-VAL to acquire tactile images, and utilizes our proposed Active Visual-Tactile Fusion Verification Network (AVTNet) to infer the softness of deformable objects and assess the reliability of each keypoint. Subsequently, the data glove translates varying degrees of softness into corresponding execution forces for the robotic dexterous hand. Finally, the robot performs manipulation at the most reliable keypoint using an appropriate force, ensuring stable and accurate deformable object manipulation.          </p>
        </div>
      </div>
    </div>
    <!--/ Dataset. -->
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop has-text-centered">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">

        <div class="columns is-centered">
          <div class="column">
            <div class="content">
              <h2 class="title is-5">Hang</h2>
              <video id="task1" controls playsinline width="100%">
                <source src="./static/videos/task1.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>

        <div class="columns is-centered">
          <div class="column">
            <div class="content">
              <h2 class="title is-5">Pick</h2>
              <video id="task2" controls playsinline width="100%">
                <source src="./static/videos/task2.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>

        <div class="columns is-centered">
          <div class="column">
            <div class="content">
              <h2 class="title is-5">Grasp sleeve</h2>
              <video id="task3" autoplay controls muted loop playsinline width="100%">
                <source src="./static/videos/task3.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>

      </div>
    </div>
  </div>
</section>




<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>. Modified upon original <a href="https://nerfies.github.io/"> Nerfies </a> website (<a href="https://github.com/nerfies/nerfies.github.io">source</a>).
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
